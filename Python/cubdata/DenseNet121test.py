import numpy as np
import pandas as pd
import os

# GPU ì„¤ì • ì¶”ê°€
import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ… GPU ì„¤ì • ì™„ë£Œ: RTX 3060 ì‚¬ìš©")
    except RuntimeError as e:
        print(f"GPU ì„¤ì • ì˜¤ë¥˜: {e}")

from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input
from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint

# ê²½ë¡œ ìˆ˜ì • (Windowsìš©)
os.chdir('C:/Users/ayaan/Documents/Git/Junior/Python/Data')
train_dir = 'ani/train'  # ì›ë˜: '/content/drive/MyDrive/AIdata/hymenoptera_data/train'
val_dir = 'ani/val'      # ì›ë˜: '/content/drive/MyDrive/AIdata/hymenoptera_data/val'

data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,
                                              horizontal_flip = True,
                                              width_shift_range = 0.1,
                                              height_shift_range = 0.1)
data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)

image_size = 224

# ë°°ì¹˜ í¬ê¸° GPUìš©ìœ¼ë¡œ ì¦ê°€
batch_size = 2  # ì›ë˜: 12

train_generator = data_generator_with_aug.flow_from_directory(
       directory = train_dir,
       target_size=(image_size, image_size),
       batch_size=batch_size,  # GPUìš© ë°°ì¹˜ í¬ê¸°
       class_mode='categorical')

validation_generator = data_generator_no_aug.flow_from_directory(
       directory = val_dir,
       target_size=(image_size, image_size),
       batch_size=batch_size,  # GPUìš© ë°°ì¹˜ í¬ê¸°
       class_mode='categorical')

# í´ë˜ìŠ¤ ìˆ˜ ìë™ ê°ì§€ (ì›ë˜: num_classes = 2)
num_classes = train_generator.num_classes

# GPUì—ì„œ ëª¨ë¸ ìƒì„±
with tf.device('/GPU:0' if gpus else '/CPU:0'):
    base_model=DenseNet121(weights='imagenet',include_top=False,input_shape=(224,224,3))
    
    cnn = Sequential()
    cnn.add(base_model)
    cnn.add(Flatten())
    cnn.add(Dense(1024,activation='relu'))
    cnn.add(Dense(num_classes,activation='softmax'))

cnn.compile(loss='categorical_crossentropy',optimizer=Adam(0.0001),metrics=['accuracy'])

# ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs('model', exist_ok=True)

# define the checkpoint
filepath = "model/model.h5"  # ì›ë˜: "model.h5"
checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')
callbacks_list = [checkpoint]

# GPUì—ì„œ í›ˆë ¨
print(f"ğŸš€ GPU í›ˆë ¨ ì‹œì‘ - ë°°ì¹˜ í¬ê¸°: {batch_size}")
with tf.device('/GPU:0' if gpus else '/CPU:0'):
    hist=cnn.fit(
            train_generator,
            epochs=20,
            validation_data=validation_generator,
            callbacks=callbacks_list,
            verbose=1  # ì›ë˜ ì½”ë“œì—ëŠ” ì—†ì—ˆì§€ë§Œ ì¶”ê°€
            )

print("ğŸ‰ í›ˆë ¨ ì™„ë£Œ!")

# ì‹œê°í™” ì¶”ê°€
import matplotlib.pyplot as plt

# ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •
plt.style.use('seaborn-v0_8-whitegrid')
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# 1. Model accuracy ê·¸ë˜í”„
ax1.plot(hist.history['accuracy'], linewidth=2, label='Train', color='#FF0000')
ax1.plot(hist.history['val_accuracy'], linewidth=2, label='Validation', color='#00FF00')
ax1.set_title('Model accuracy', fontsize=14, fontweight='bold')
ax1.set_xlabel('Epoch', fontsize=12)
ax1.set_ylabel('Accuracy', fontsize=12)
ax1.legend(fontsize=11)
ax1.grid(True, alpha=0.3)
ax1.set_ylim(0, 1.0)

# 2. Model loss ê·¸ë˜í”„  
ax2.plot(hist.history['loss'], linewidth=2, label='Train', color='#FF0000')
ax2.plot(hist.history['val_loss'], linewidth=2, label='Validation', color='#00FF00')
ax2.set_title('Model loss', fontsize=14, fontweight='bold')
ax2.set_xlabel('Epoch', fontsize=12)
ax2.set_ylabel('Loss', fontsize=12)
ax2.legend(fontsize=11)
ax2.grid(True, alpha=0.3)

# ë ˆì´ì•„ì›ƒ ì¡°ì •
plt.tight_layout()

# ê·¸ë˜í”„ ì €ì¥
plt.savefig('model/training_results.png', dpi=300, bbox_inches='tight')
plt.show()

# ìµœì¢… ê²°ê³¼ ì¶œë ¥
final_train_acc = hist.history['accuracy'][-1]
final_val_acc = hist.history['val_accuracy'][-1]
best_val_acc = max(hist.history['val_accuracy'])

print(f"ğŸ“Š ìµœì¢… í›ˆë ¨ ì •í™•ë„: {final_train_acc:.4f}")
print(f"ğŸ“Š ìµœì¢… ê²€ì¦ ì •í™•ë„: {final_val_acc:.4f}") 
print(f"ğŸ† ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.4f}")
print(f"ğŸ’¾ ê·¸ë˜í”„ ì €ì¥: model/training_results.png")