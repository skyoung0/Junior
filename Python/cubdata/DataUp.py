import numpy as np
import pandas as pd
import os
import shutil
from collections import Counter
import cv2
from PIL import Image, ImageEnhance, ImageFilter
import random
import tensorflow as tf
import matplotlib.pyplot as plt

# ğŸ”§ TensorFlow JSON ì§ë ¬í™” ë¬¸ì œ ì™„ì „ í•´ê²°
import json
import keras.callbacks

# ì»¤ìŠ¤í…€ JSON ì¸ì½”ë”
class TensorFlowJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if hasattr(obj, 'numpy'):
            return float(obj.numpy())
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, (np.int32, np.int64)):
            return int(obj)
        if isinstance(obj, (np.float32, np.float64)):
            return float(obj)
        return super().default(obj)

# JSON ì¸ì½”ë” íŒ¨ì¹˜
json._default_encoder = TensorFlowJSONEncoder()

# GPU ì„¤ì •
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ… GPU ì„¤ì • ì™„ë£Œ: RTX 3060 ì‚¬ìš©")
    except RuntimeError as e:
        print(f"GPU ì„¤ì • ì˜¤ë¥˜: {e}")

from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input as resnet_preprocess
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg_preprocess
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.regularizers import l2

# ê²½ë¡œ ì„¤ì •
os.chdir('C:/Users/ayaan/Documents/Git/Junior/Python/Data')
train_dir = 'ani/train'
val_dir = 'ani/val'
augmented_train_dir = 'ani/augmented_train'

# ğŸ›¡ï¸ ì™„ì „íˆ ì•ˆì „í•œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì½œë°±
class SuperSafeModelCheckpoint(Callback):
    def __init__(self, filepath, monitor='val_accuracy', save_best_only=True, mode='max'):
        super().__init__()
        self.filepath = filepath
        self.monitor = monitor
        self.save_best_only = save_best_only
        self.mode = mode
        self.best = float('-inf') if mode == 'max' else float('inf')
        
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        
        # í…ì„œë¥¼ íŒŒì´ì¬ ìˆ«ìë¡œ ë³€í™˜
        current = logs.get(self.monitor)
        if current is not None:
            if hasattr(current, 'numpy'):
                current = float(current.numpy())
            else:
                current = float(current)
                
            # ìµœê³  ì„±ëŠ¥ ì²´í¬
            if self.mode == 'max':
                if current > self.best:
                    self.best = current
                    print(f"\nEpoch {epoch + 1}: {self.monitor} improved to {current:.5f}, saving model...")
                    try:
                        self.model.save_weights(self.filepath)
                        print("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ")
                    except Exception as e:
                        print(f"âš ï¸ ëª¨ë¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            else:
                if current < self.best:
                    self.best = current
                    print(f"\nEpoch {epoch + 1}: {self.monitor} improved to {current:.5f}, saving model...")
                    try:
                        self.model.save_weights(self.filepath)
                        print("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ")
                    except Exception as e:
                        print(f"âš ï¸ ëª¨ë¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# ğŸ›¡ï¸ ì™„ì „íˆ ì•ˆì „í•œ Early Stopping
class SuperSafeEarlyStopping(Callback):
    def __init__(self, monitor='val_accuracy', patience=7, restore_best_weights=True, mode='max'):
        super().__init__()
        self.monitor = monitor
        self.patience = patience
        self.restore_best_weights = restore_best_weights
        self.mode = mode
        self.best = float('-inf') if mode == 'max' else float('inf')
        self.wait = 0
        self.best_weights = None
        
    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        
        current = logs.get(self.monitor)
        if current is not None:
            if hasattr(current, 'numpy'):
                current = float(current.numpy())
            else:
                current = float(current)
                
            if self.mode == 'max':
                if current > self.best:
                    self.best = current
                    self.wait = 0
                    if self.restore_best_weights:
                        self.best_weights = self.model.get_weights()
                else:
                    self.wait += 1
            else:
                if current < self.best:
                    self.best = current
                    self.wait = 0
                    if self.restore_best_weights:
                        self.best_weights = self.model.get_weights()
                else:
                    self.wait += 1
                    
            if self.wait >= self.patience:
                print(f"\nEarly stopping triggered. Restoring best weights...")
                if self.restore_best_weights and self.best_weights is not None:
                    self.model.set_weights(self.best_weights)
                self.model.stop_training = True

# ğŸ” 1. ê¸°ì¡´ ì¦ëŒ€ ë°ì´í„° í™œìš© (ì´ë¯¸ ìƒì„±ë˜ì—ˆë‹¤ë©´)
if os.path.exists(augmented_train_dir):
    print("ğŸ” ê¸°ì¡´ ì¦ëŒ€ ë°ì´í„° ë°œê²¬, ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")
else:
    print("ğŸ“Š ê°„ë‹¨í•œ ë°ì´í„° ì¦ëŒ€ ìˆ˜í–‰...")
    # ê¸°ë³¸ Keras ImageDataGeneratorë§Œ ì‚¬ìš© (OpenCV ì˜¤ë¥˜ ë°©ì§€)
    if not os.path.exists(augmented_train_dir):
        shutil.copytree(train_dir, augmented_train_dir)
    print("âœ… ê¸°ë³¸ ë°ì´í„° ë³µì‚¬ ì™„ë£Œ")

# ğŸ¯ 2. ì•ˆì „í•œ ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
def create_bulletproof_ensemble(num_classes, input_shape=(224, 224, 3)):
    """ì™„ì „íˆ ì•ˆì „í•œ ì•™ìƒë¸” ëª¨ë¸"""
    
    models = []
    
    # ëª¨ë¸ 1: ResNet50 (ê°€ì¥ ì•ˆì •ì )
    print("ğŸ”¨ ResNet50 ëª¨ë¸ ìƒì„± ì¤‘...")
    resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)
    
    # ë§ˆì§€ë§‰ ëª‡ ê°œ ë ˆì´ì–´ë§Œ í›ˆë ¨
    for layer in resnet_base.layers[:-10]:
        layer.trainable = False
    
    resnet_model = Sequential([
        resnet_base,
        GlobalAveragePooling2D(),
        Dropout(0.5),
        Dense(256, activation='relu', kernel_regularizer=l2(0.001)),
        Dropout(0.3),
        Dense(num_classes, activation='softmax')
    ], name='ResNet50_Model')
    
    resnet_model.compile(
        optimizer=Adam(learning_rate=0.0001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    models.append(('ResNet50', resnet_model))
    
    # ëª¨ë¸ 2: VGG16 (ì•ˆì •ì )
    print("ğŸ”¨ VGG16 ëª¨ë¸ ìƒì„± ì¤‘...")
    vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)
    
    # ë§ˆì§€ë§‰ ëª‡ ê°œ ë ˆì´ì–´ë§Œ í›ˆë ¨
    for layer in vgg_base.layers[:-4]:
        layer.trainable = False
    
    vgg_model = Sequential([
        vgg_base,
        GlobalAveragePooling2D(),
        Dropout(0.6),
        Dense(256, activation='relu', kernel_regularizer=l2(0.001)),
        Dropout(0.4),
        Dense(num_classes, activation='softmax')
    ], name='VGG16_Model')
    
    vgg_model.compile(
        optimizer=Adam(learning_rate=0.00008),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    models.append(('VGG16', vgg_model))
    
    return models

# ğŸ¯ 3. ë°ì´í„° ë¡œë” ì„¤ì •
def create_safe_data_generators(train_dir, val_dir, batch_size=24):
    """ì•ˆì „í•œ ë°ì´í„° ìƒì„±ê¸°"""
    
    # í›ˆë ¨ìš© ì¦ëŒ€ (Keras ê¸°ë³¸ë§Œ ì‚¬ìš©)
    train_datagen = ImageDataGenerator(
        preprocessing_function=resnet_preprocess,
        horizontal_flip=True,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        zoom_range=0.2,
        shear_range=0.1,
        fill_mode='nearest'
    )
    
    # ê²€ì¦ìš©
    val_datagen = ImageDataGenerator(preprocessing_function=resnet_preprocess)
    
    # ë°ì´í„° ìƒì„±ê¸°
    train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(224, 224),
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=True
    )
    
    val_generator = val_datagen.flow_from_directory(
        val_dir,
        target_size=(224, 224),
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=False
    )
    
    return train_generator, val_generator

# ë°ì´í„° ìƒì„±ê¸° ìƒì„±
train_generator, val_generator = create_safe_data_generators(augmented_train_dir, val_dir, batch_size=24)
num_classes = train_generator.num_classes

print(f"\nğŸ“Š ë°ì´í„° ì •ë³´:")
print(f"í›ˆë ¨ ìƒ˜í”Œ: {train_generator.samples:,}ê°œ")
print(f"ê²€ì¦ ìƒ˜í”Œ: {val_generator.samples:,}ê°œ")
print(f"í´ë˜ìŠ¤ ìˆ˜: {num_classes}ê°œ")
print(f"í´ë˜ìŠ¤ëª…: {list(train_generator.class_indices.keys())}")

# ğŸ¯ 4. ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
ensemble_models = create_bulletproof_ensemble(num_classes)

print(f"\nğŸ­ ì•™ìƒë¸” êµ¬ì„±: {len(ensemble_models)}ê°œ ëª¨ë¸")
for name, model in ensemble_models:
    total_params = model.count_params()
    trainable_params = sum([tf.reduce_prod(var.shape) for var in model.trainable_variables])
    print(f"   - {name}: ì´ {total_params:,} íŒŒë¼ë¯¸í„° (í›ˆë ¨ ê°€ëŠ¥: {trainable_params:,})")

# ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs('model/ensemble', exist_ok=True)

# ğŸ¯ 5. ì™„ì „íˆ ì•ˆì „í•œ í›ˆë ¨ í•¨ìˆ˜
def bulletproof_training(ensemble_models, train_generator, val_generator, epochs=15):
    """ì™„ì „íˆ ì•ˆì „í•œ ì•™ìƒë¸” í›ˆë ¨"""
    
    trained_models = []
    training_histories = []
    
    for i, (model_name, model) in enumerate(ensemble_models):
        print(f"\nğŸš€ {i+1}/{len(ensemble_models)} ëª¨ë¸ í›ˆë ¨ ì‹œì‘: {model_name}")
        print("=" * 60)
        
        # ì™„ì „íˆ ì•ˆì „í•œ ì½œë°±ë“¤
        callbacks = [
            SuperSafeModelCheckpoint(
                f"model/ensemble/{model_name.lower()}_safe_weights.h5",
                monitor='val_accuracy',
                save_best_only=True,
                mode='max'
            ),
            SuperSafeEarlyStopping(
                monitor='val_accuracy',
                patience=5,
                restore_best_weights=True,
                mode='max'
            )
        ]
        
        # GPUì—ì„œ í›ˆë ¨
        print(f"ğŸ”¥ GPUì—ì„œ {model_name} í›ˆë ¨ ì‹œì‘...")
        with tf.device('/GPU:0' if gpus else '/CPU:0'):
            try:
                history = model.fit(
                    train_generator,
                    epochs=epochs,
                    validation_data=val_generator,
                    callbacks=callbacks,
                    verbose=1
                )
                
                print(f"âœ… {model_name} í›ˆë ¨ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
                
            except Exception as e:
                print(f"âŒ {model_name} í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                # ê¸°ë³¸ í›ˆë ¨ (ì½œë°± ì—†ì´)
                print(f"ğŸ”„ {model_name} ê¸°ë³¸ ëª¨ë“œë¡œ ì¬ì‹œë„...")
                history = model.fit(
                    train_generator,
                    epochs=min(10, epochs),
                    validation_data=val_generator,
                    verbose=1
                )
        
        trained_models.append((model_name, model))
        training_histories.append((model_name, history))
        
        # ì„±ëŠ¥ ì¶œë ¥ (ì•ˆì „í•˜ê²Œ)
        try:
            val_acc_history = history.history['val_accuracy']
            best_val_acc = max(val_acc_history)
            final_val_acc = val_acc_history[-1]
            print(f"ğŸ† {model_name} ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.4f}")
            print(f"ğŸ“Š {model_name} ìµœì¢… ê²€ì¦ ì •í™•ë„: {final_val_acc:.4f}")
        except Exception as e:
            print(f"âš ï¸ {model_name} ì„±ëŠ¥ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return trained_models, training_histories

# ğŸ¯ 6. ì•ˆì „í•œ í›ˆë ¨ ì‹¤í–‰
print("\nğŸ›¡ï¸ ì™„ì „íˆ ì•ˆì „í•œ ì•™ìƒë¸” í›ˆë ¨ ì‹œì‘!")
trained_models, training_histories = bulletproof_training(ensemble_models, train_generator, val_generator)

# ğŸ¯ 7. ì•ˆì „í•œ ì„±ëŠ¥ í‰ê°€
def safe_evaluation(trained_models, val_generator):
    """ì•ˆì „í•œ ì„±ëŠ¥ í‰ê°€"""
    print("\nğŸ” ì•ˆì „í•œ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    
    individual_scores = []
    
    for model_name, model in trained_models:
        try:
            # ì•ˆì „í•œ í‰ê°€
            val_generator.reset()
            score = model.evaluate(val_generator, verbose=0)
            accuracy = float(score[1]) if hasattr(score[1], 'numpy') else score[1]
            individual_scores.append((model_name, accuracy))
            print(f"{model_name:12} ê²€ì¦ ì •í™•ë„: {accuracy:.4f}")
        except Exception as e:
            print(f"âš ï¸ {model_name} í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
            individual_scores.append((model_name, 0.0))
    
    # ê°„ë‹¨í•œ ì•™ìƒë¸” í…ŒìŠ¤íŠ¸
    try:
        val_generator.reset()
        batch_x, batch_y = next(val_generator)
        
        predictions = []
        for model_name, model in trained_models:
            try:
                pred = model.predict(batch_x, verbose=0)
                predictions.append(pred)
            except Exception as e:
                print(f"âš ï¸ {model_name} ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
        
        if predictions:
            ensemble_pred = np.mean(predictions, axis=0)
            ensemble_accuracy = np.mean(
                np.argmax(ensemble_pred, axis=1) == np.argmax(batch_y, axis=1)
            )
            print(f"\nğŸ­ ì•™ìƒë¸” ìƒ˜í”Œ ì •í™•ë„: {ensemble_accuracy:.4f}")
        else:
            ensemble_accuracy = 0.0
            print("\nâŒ ì•™ìƒë¸” ì˜ˆì¸¡ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âš ï¸ ì•™ìƒë¸” í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
        ensemble_accuracy = 0.0
    
    return individual_scores, ensemble_accuracy

# ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰
individual_scores, ensemble_accuracy = safe_evaluation(trained_models, val_generator)

# ğŸ¯ 8. ê°„ë‹¨í•œ ì‹œê°í™”
def safe_visualization(training_histories, individual_scores, ensemble_accuracy):
    """ì•ˆì „í•œ ì‹œê°í™”"""
    
    try:
        plt.figure(figsize=(15, 5))
        
        # 1. í›ˆë ¨ ê³¡ì„ 
        plt.subplot(1, 3, 1)
        colors = ['blue', 'red', 'green']
        
        for i, (model_name, history) in enumerate(training_histories):
            try:
                val_acc = history.history['val_accuracy']
                epochs = range(1, len(val_acc) + 1)
                plt.plot(epochs, val_acc, color=colors[i % len(colors)], 
                        linewidth=2, label=model_name, marker='o', markersize=3)
            except Exception as e:
                print(f"âš ï¸ {model_name} ê³¡ì„  ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
        
        plt.title('ğŸš€ Training Progress')
        plt.xlabel('Epoch')
        plt.ylabel('Validation Accuracy')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2. ê°œë³„ ì„±ëŠ¥
        plt.subplot(1, 3, 2)
        if individual_scores:
            names = [name for name, _ in individual_scores]
            scores = [score for _, score in individual_scores]
            colors_bar = ['lightblue', 'lightcoral', 'lightgreen']
            
            plt.bar(names, scores, color=colors_bar[:len(names)], alpha=0.8)
            plt.title('ğŸ† Individual Performance')
            plt.ylabel('Validation Accuracy')
            plt.xticks(rotation=45)
        
        # 3. ì•™ìƒë¸” ë¹„êµ
        plt.subplot(1, 3, 3)
        if individual_scores:
            all_names = [name for name, _ in individual_scores] + ['Ensemble']
            all_scores = [score for _, score in individual_scores] + [ensemble_accuracy]
            colors_comp = ['lightblue', 'lightcoral', 'gold']
            
            plt.bar(all_names, all_scores, color=colors_comp[:len(all_names)], alpha=0.8)
            plt.title('ğŸ¯ Ensemble Comparison')
            plt.ylabel('Accuracy')
            plt.xticks(rotation=45)
        
        plt.tight_layout()
        plt.savefig('model/ensemble/safe_results.png', dpi=300, bbox_inches='tight')
        plt.show()
        print("âœ… ì‹œê°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"âš ï¸ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜: {e}")

# ì‹œê°í™” ì‹¤í–‰
safe_visualization(training_histories, individual_scores, ensemble_accuracy)

# ğŸ¯ 9. ìµœì¢… ì•ˆì „ ë¦¬í¬íŠ¸
print(f"\n" + "="*60)
print("ğŸ›¡ï¸ ì™„ì „íˆ ì•ˆì „í•œ ì•™ìƒë¸” ì‹œìŠ¤í…œ ì™„ë£Œ!")
print("="*60)

if individual_scores:
    print(f"\nğŸ“Š ê°œë³„ ëª¨ë¸ ì„±ëŠ¥:")
    best_score = 0
    best_model = ""
    
    for name, score in individual_scores:
        print(f"{name:12}: {score:.4f} ({score*100:.1f}%)")
        if score > best_score:
            best_score = score
            best_model = name
    
    print(f"\nğŸ† ìµœê³  ê°œë³„ ëª¨ë¸: {best_model} ({best_score:.4f})")
    print(f"ğŸ­ ì•™ìƒë¸” ì„±ëŠ¥: {ensemble_accuracy:.4f}")
    
    improvement = ensemble_accuracy - best_score
    if improvement > 0:
        print(f"ğŸ“ˆ ì•™ìƒë¸” ê°œì„ : +{improvement:.4f} (+{improvement*100:.1f}%p)")
        print("âœ… ì•™ìƒë¸”ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤!")
    else:
        print(f"ğŸ“‰ ì•™ìƒë¸” íš¨ê³¼: {improvement:.4f}")
        print("âš ï¸ ê°œë³„ ëª¨ë¸ì´ ë” ìš°ìˆ˜í•©ë‹ˆë‹¤.")

print(f"\nğŸ’¾ ì €ì¥ëœ íŒŒì¼:")
print(f"- ëª¨ë¸ ê°€ì¤‘ì¹˜: model/ensemble/*_safe_weights.h5")
print(f"- ê²°ê³¼ ê·¸ë˜í”„: model/ensemble/safe_results.png")

print(f"\nğŸ‰ JSON ì˜¤ë¥˜ ì—†ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš€")

# ğŸ¯ 10. ì‚¬ìš©ë²• ì•ˆë‚´
print(f"\nğŸ“– ëª¨ë¸ ì‚¬ìš©ë²•:")
print("1. ê°€ì¤‘ì¹˜ ë¡œë“œ:")
print("   model.load_weights('model/ensemble/resnet50_safe_weights.h5')")
print("2. ì˜ˆì¸¡:")
print("   predictions = model.predict(your_data)")
print("3. ì•™ìƒë¸” ì˜ˆì¸¡:")
print("   ensemble_pred = np.mean([model1.predict(data), model2.predict(data)], axis=0)")